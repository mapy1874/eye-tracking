{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %%\n",
    "from cnn_utils import *\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.engine import  Model\n",
    "from keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D\n",
    "from keras_vggface.vggface import VGGFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the installation of Keras VGGFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/usr/local/anaconda3/envs/deeplearning/bin/python\n"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6\n"
    }
   ],
   "source": [
    "# check version of keras_vggface\n",
    "import keras_vggface\n",
    "# print version\n",
    "print(keras_vggface.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                            eyeImage  \\\n0  [[[0.49019607843137253, 0.4627450980392157, 0....   \n1  [[[0.19607843137254902, 0.1607843137254902, 0....   \n2  [[[0.2196078431372549, 0.19215686274509805, 0....   \n3  [[[0.2196078431372549, 0.17647058823529413, 0....   \n4  [[[0.5882352941176471, 0.5647058823529412, 0.6...   \n\n                                             leftEye  \\\n0  [-0.06916704732662149, 0.19730078279591035, -0...   \n1  [-0.17658285534307594, 0.18033866676032262, -0...   \n2  [-0.17382043840055927, 0.17981051564675177, -0...   \n3  [-0.15968611544730582, 0.18524077990937093, -0...   \n4  [-0.07825260742468576, 0.16963032408957468, -0...   \n\n                                            rightEye  \\\n0  [0.17425771877389162, 0.21639015714266296, 0.2...   \n1  [0.06629549190581052, 0.1988126179958256, 0.10...   \n2  [0.06089991895895852, 0.18628686237123016, 0.0...   \n3  [0.08123800929222913, 0.1904861112443328, 0.11...   \n4  [0.1666792245722788, 0.19617187288354976, 0.20...   \n\n                                             y  \n0  [-0.30000000000000004, -0.3019517795637199]  \n1   [0.30000000000000004, -0.9012629161882894]  \n2    [0.8999999999999999, -0.9012629161882894]  \n3   [-0.30000000000000004, 0.8989667049368542]  \n4   [-0.30000000000000004, 0.2996555683122848]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eyeImage</th>\n      <th>leftEye</th>\n      <th>rightEye</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[[0.49019607843137253, 0.4627450980392157, 0....</td>\n      <td>[-0.06916704732662149, 0.19730078279591035, -0...</td>\n      <td>[0.17425771877389162, 0.21639015714266296, 0.2...</td>\n      <td>[-0.30000000000000004, -0.3019517795637199]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[[0.19607843137254902, 0.1607843137254902, 0....</td>\n      <td>[-0.17658285534307594, 0.18033866676032262, -0...</td>\n      <td>[0.06629549190581052, 0.1988126179958256, 0.10...</td>\n      <td>[0.30000000000000004, -0.9012629161882894]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[[0.2196078431372549, 0.19215686274509805, 0....</td>\n      <td>[-0.17382043840055927, 0.17981051564675177, -0...</td>\n      <td>[0.06089991895895852, 0.18628686237123016, 0.0...</td>\n      <td>[0.8999999999999999, -0.9012629161882894]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[[0.2196078431372549, 0.17647058823529413, 0....</td>\n      <td>[-0.15968611544730582, 0.18524077990937093, -0...</td>\n      <td>[0.08123800929222913, 0.1904861112443328, 0.11...</td>\n      <td>[-0.30000000000000004, 0.8989667049368542]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[[0.5882352941176471, 0.5647058823529412, 0.6...</td>\n      <td>[-0.07825260742468576, 0.16963032408957468, -0...</td>\n      <td>[0.1666792245722788, 0.19617187288354976, 0.20...</td>\n      <td>[-0.30000000000000004, 0.2996555683122848]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = create_dataframe('/../raw_data/dataset_062920.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "846"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to use Quaternary encoding to see if we have mislabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select training examples\n",
    "x_train, x_validation, y_train, y_validation = create_train_validation(df)\n",
    "\n",
    "# generate binary y labels\n",
    "# y_train_binary = create_binary_labels(y_train)\n",
    "# y_validation_binary = create_binary_labels(y_validation) # generate binary y labels\n",
    "\n",
    "# generate quaternary y labels\n",
    "y_train_quaternary = create_quaternary_labels(y_train)\n",
    "y_validation_quaternary = create_quaternary_labels(y_validation) # generate binary y labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      y\n6    LR\n13   UL\n29   LR\n33   LR\n34   UL\n..   ..\n833  LL\n836  UR\n838  LL\n842  LL\n845  LL\n\n[169 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>LR</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>UL</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>LR</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>LR</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>UL</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>833</th>\n      <td>LL</td>\n    </tr>\n    <tr>\n      <th>836</th>\n      <td>UR</td>\n    </tr>\n    <tr>\n      <th>838</th>\n      <td>LL</td>\n    </tr>\n    <tr>\n      <th>842</th>\n      <td>LL</td>\n    </tr>\n    <tr>\n      <th>845</th>\n      <td>LL</td>\n    </tr>\n  </tbody>\n</table>\n<p>169 rows Ã— 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "y_validation_quaternary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some data\n",
    "# plot_eyeImages(x_train,y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for feeding in CNN\n",
    "eyeImage_train, leftEye_train, rightEye_train, quaternary_train = create_tf_data(x_train, y_train_quaternary)\n",
    "eyeImage_test, leftEye_test, rightEye_test, quaternary_test = create_tf_data(x_validation, y_validation_quaternary)\n",
    "\n",
    "\n",
    "# encoding the data\n",
    "# binary_encoder = LabelEncoder()\n",
    "# binary_encoder.fit(binary_train)\n",
    "# binary_train = binary_encoder.transform(binary_train)\n",
    "# binary_test = binary_encoder.transform(binary_test)\n",
    "\n",
    "# # one-hot encoding the data\n",
    "# binary_train = to_categorical(binary_train)\n",
    "# binary_test = to_categorical(binary_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['UL', 'UR', 'UR', 'LL', 'LL', 'LL', 'UR', 'LL', 'LR', 'LR', 'LR',\n       'UR', 'UL', 'LL', 'UL', 'LL', 'UR', 'UR', 'LL', 'LL', 'LR', 'UL',\n       'UL', 'UL', 'UR', 'LR', 'UR', 'LR', 'UR', 'LR', 'LR', 'LL', 'UR',\n       'UL', 'UR', 'LL', 'UL', 'UR', 'LR', 'UL', 'LL', 'UR', 'UL', 'LR',\n       'UL', 'LL', 'UR', 'LR', 'LL', 'UR', 'LR', 'LL', 'LL', 'LR', 'UL',\n       'UR', 'LR', 'UR', 'UL', 'UL', 'LL', 'UR', 'LR', 'LR', 'UL', 'LR',\n       'UL', 'LL', 'LR', 'LL', 'UR', 'UR', 'LR', 'UL', 'LL', 'UR', 'LL',\n       'LR', 'LL', 'LL', 'LL', 'UL', 'LL', 'UL', 'UL', 'UR', 'LR', 'LL',\n       'LR', 'UL', 'LR', 'UR', 'LR', 'UR', 'LL', 'LR', 'LR', 'UL', 'LL',\n       'LR', 'UR', 'LL', 'UL', 'UL', 'UR', 'LL', 'LL', 'UR', 'UL', 'UL',\n       'UR', 'LR', 'LL', 'LL', 'LL', 'LL', 'UL', 'UR', 'LR', 'LL', 'LR',\n       'UR', 'LL', 'UL', 'UL', 'UR', 'UR', 'LR', 'LL', 'UR', 'LL', 'LR',\n       'UL', 'LL', 'UR', 'UL', 'LL', 'UL', 'UL', 'LR', 'LL', 'UR', 'UR',\n       'UL', 'UL', 'UR', 'LL', 'UL', 'LR', 'LL', 'LL', 'LL', 'LR', 'LR',\n       'UR', 'UL', 'UR', 'LL', 'LR', 'LL', 'LR', 'LR', 'UL', 'UL', 'LL',\n       'UR', 'LL', 'UL', 'LL', 'UR', 'LR', 'LR', 'UL', 'UL', 'UL', 'UR',\n       'LR', 'UR', 'LR', 'LR', 'LL', 'LL', 'LR', 'UL', 'LL', 'LR', 'LR',\n       'UR', 'LL', 'UL', 'UL', 'UR', 'LR', 'LL', 'LL', 'UL', 'UL', 'LR',\n       'LR', 'UR', 'UR', 'UR', 'LL', 'UL', 'UL', 'UL', 'LL', 'LL', 'LL',\n       'UL', 'UL', 'UR', 'LR', 'UL', 'LL', 'LR', 'LL', 'UR', 'LR', 'UR',\n       'UL', 'UL', 'LR', 'LL', 'UR', 'LL', 'UR', 'LL', 'LR', 'LR', 'UL',\n       'UL', 'UL', 'LR', 'LL', 'UR', 'UL', 'LL', 'LR', 'LL', 'UL', 'UR',\n       'LL', 'UR', 'LR', 'LR', 'UR', 'UL', 'LL', 'UL', 'UL', 'LR', 'LR',\n       'LL', 'LL', 'LL', 'LR', 'UL', 'UR', 'UL', 'LL', 'LL', 'LL', 'UL',\n       'LR', 'LR', 'UR', 'LL', 'UR', 'UL', 'UL', 'LR', 'LL', 'UR', 'UR',\n       'UR', 'LR', 'LL', 'UL', 'LR', 'UL', 'UR', 'UR', 'LR', 'LL', 'UR',\n       'LR', 'LR', 'UL', 'LL', 'UL', 'UR', 'UR', 'LR', 'UL', 'UL', 'LL',\n       'LR', 'LL', 'UR', 'UR', 'LL', 'LL', 'UR', 'LR', 'LL', 'UL', 'UR',\n       'LR', 'UR', 'LL', 'LL', 'LL', 'LL', 'LL', 'LR', 'LR', 'UL', 'UL',\n       'UR', 'UR', 'UL', 'LR', 'LR', 'UL', 'UR', 'LL', 'UR', 'LL', 'LL',\n       'UL', 'UR', 'LR', 'LR', 'UR', 'LR', 'UL', 'UR', 'LL', 'UL', 'LL',\n       'UR', 'UL', 'LL', 'UR', 'UL', 'LR', 'UL', 'UR', 'LR', 'LL', 'LL',\n       'LL', 'LR', 'LR', 'UL', 'LR', 'LR', 'LL', 'UL', 'LR', 'LL', 'LL',\n       'UR', 'UL', 'UR', 'LR', 'UR', 'LL', 'LL', 'LL', 'LL', 'UR', 'UL',\n       'LL', 'LR', 'UL', 'UR', 'LR', 'UL', 'UR', 'LR', 'UL', 'LL', 'UL',\n       'LR', 'UL', 'LL', 'UR', 'LL', 'UR', 'LR', 'LR', 'LL', 'UR', 'LL',\n       'LL', 'UL', 'UL', 'UL', 'LL', 'LR', 'LL', 'UL', 'LR', 'LR', 'UR',\n       'LR', 'UR', 'UR', 'LR', 'UL', 'UL', 'LR', 'UR', 'LR', 'LL', 'UL',\n       'LL', 'UR', 'UL', 'LR', 'UL', 'UR', 'UL', 'LL', 'LR', 'LL', 'LR',\n       'UR', 'UL', 'LL', 'LL', 'UR', 'UR', 'LR', 'UR', 'UR', 'LL', 'LR',\n       'LR', 'UL', 'LL', 'UL', 'LR', 'LL', 'UL', 'LL', 'UL', 'LR', 'UL',\n       'LR', 'LL', 'LL', 'UR', 'LR', 'LR', 'LL', 'UL', 'LL', 'UR', 'LL',\n       'UL', 'LR', 'UR', 'UL', 'UR', 'LR', 'UR', 'UR', 'UL', 'LL', 'LR',\n       'UR', 'UL', 'LR', 'LL', 'LR', 'UL', 'UL', 'LR', 'LL', 'LL', 'UL',\n       'LR', 'UR', 'LR', 'LL', 'UL', 'UL', 'UR', 'UL', 'UR', 'UR', 'LR',\n       'UL', 'UL', 'LL', 'UR', 'UR', 'LL', 'LR', 'LR', 'LR', 'UR', 'LL',\n       'LR', 'LR', 'UR', 'LR', 'LL', 'UR', 'UL', 'LR', 'UL', 'LL', 'UL',\n       'LR', 'UR', 'UL', 'LL', 'UL', 'UR', 'LL', 'LR', 'UL', 'UR', 'LR',\n       'LL', 'LR', 'LL', 'UL', 'UR', 'UL', 'LR', 'LL', 'UR', 'UR', 'LL',\n       'UL', 'UR', 'LR', 'LL', 'UL', 'UL', 'LR', 'LL', 'LR', 'LR', 'LL',\n       'UR', 'LR', 'UR', 'UL', 'UL', 'UL', 'UL', 'LR', 'UR', 'UR', 'LL',\n       'UR', 'LL', 'LL', 'UR', 'UL', 'LL', 'UR', 'UL', 'UL', 'UL', 'LR',\n       'LR', 'UR', 'UR', 'LR', 'LL', 'LL', 'LR', 'UR', 'UL', 'UL', 'UR',\n       'UL', 'LR', 'LL', 'UL', 'LR', 'LR', 'UR', 'UR', 'UL', 'UL', 'UL',\n       'UR', 'LL', 'LR', 'UR', 'LR', 'LR', 'UR', 'UL', 'LR', 'LL', 'LR',\n       'LR', 'UR', 'UR', 'UL', 'UL', 'LL', 'UR', 'UL', 'UR', 'LL', 'UL',\n       'UR', 'LR', 'UR', 'UL', 'LL', 'LR', 'UR', 'LL', 'LR', 'LL', 'LL',\n       'UL', 'LL', 'LR', 'UR', 'UL', 'UR', 'LR', 'LR', 'LL', 'UR', 'UR',\n       'UL', 'LL', 'LL', 'UL', 'LR', 'LL', 'UR', 'UR', 'UR', 'LR', 'UL',\n       'LR', 'LL', 'LR', 'LR', 'LR', 'UL', 'UL', 'UR', 'LL', 'UL', 'LL',\n       'LL', 'UL', 'UR', 'UR', 'UR', 'UL', 'LR', 'LL', 'LR', 'UL', 'LR',\n       'UR', 'UL', 'UL', 'UR', 'LR', 'UR'], dtype='<U2')"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "quaternary_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quaternary_encoder = LabelEncoder()\n",
    "quaternary_encoder.fit(quaternary_train)\n",
    "quaternary_train = quaternary_encoder.transform(quaternary_train)\n",
    "quaternary_test = quaternary_encoder.transform(quaternary_test)\n",
    "\n",
    "# one-hot encoding the data\n",
    "quaternary_train = tf.keras.utils.to_categorical(quaternary_train)\n",
    "quaternary_test = tf.keras.utils.to_categorical(quaternary_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 0., 1.],\n       ...,\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "quaternary_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGFace2 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = VGGFace(model='resnet50',input_shape=(224,224,3),include_top=False,weights='vggface', pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "                 \n__________________________________________________________________________________________________\nconv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_22[0][0]              \n__________________________________________________________________________________________________\nconv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_23[0][0]              \n__________________________________________________________________________________________________\nconv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_24[0][0]              \n__________________________________________________________________________________________________\nconv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_22[0][0]              \n__________________________________________________________________________________________________\nconv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nconv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n                                                                 conv4_1_1x1_proj/bn[0][0]        \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n__________________________________________________________________________________________________\nconv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_25[0][0]              \n__________________________________________________________________________________________________\nconv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_26[0][0]              \n__________________________________________________________________________________________________\nconv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_27[0][0]              \n__________________________________________________________________________________________________\nconv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n                                                                 activation_25[0][0]              \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n__________________________________________________________________________________________________\nconv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_28[0][0]              \n__________________________________________________________________________________________________\nconv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_29[0][0]              \n__________________________________________________________________________________________________\nconv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_30[0][0]              \n__________________________________________________________________________________________________\nconv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n                                                                 activation_28[0][0]              \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n__________________________________________________________________________________________________\nconv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_31[0][0]              \n__________________________________________________________________________________________________\nconv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_32[0][0]              \n__________________________________________________________________________________________________\nconv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_33[0][0]              \n__________________________________________________________________________________________________\nconv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n                                                                 activation_31[0][0]              \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n__________________________________________________________________________________________________\nconv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_34[0][0]              \n__________________________________________________________________________________________________\nconv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_35[0][0]              \n__________________________________________________________________________________________________\nconv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_36[0][0]              \n__________________________________________________________________________________________________\nconv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n                                                                 activation_34[0][0]              \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n__________________________________________________________________________________________________\nconv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_37[0][0]              \n__________________________________________________________________________________________________\nconv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_38[0][0]              \n__________________________________________________________________________________________________\nconv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_39[0][0]              \n__________________________________________________________________________________________________\nconv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n                                                                 activation_37[0][0]              \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n__________________________________________________________________________________________________\nconv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_40[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_41[0][0]              \n__________________________________________________________________________________________________\nconv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_42[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_40[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nconv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n                                                                 conv5_1_1x1_proj/bn[0][0]        \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n__________________________________________________________________________________________________\nconv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_43[0][0]              \n__________________________________________________________________________________________________\nconv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_44[0][0]              \n__________________________________________________________________________________________________\nconv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_45[0][0]              \n__________________________________________________________________________________________________\nconv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n                                                                 activation_43[0][0]              \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n__________________________________________________________________________________________________\nconv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_46[0][0]              \n__________________________________________________________________________________________________\nconv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_47[0][0]              \n__________________________________________________________________________________________________\nconv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_48[0][0]              \n__________________________________________________________________________________________________\nconv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_16 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n                                                                 activation_46[0][0]              \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n__________________________________________________________________________________________________\navg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n==================================================================================================\nTotal params: 23,561,152\nTrainable params: 23,508,032\nNon-trainable params: 53,120\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "baseModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.get_layer('avg_pool').output\n",
    "headModel = Flatten(name='flatten')(headModel)\n",
    "headModel = Dense(4, activation='softmax', name='classifier')(headModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ce[0][0]         \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_23[0][0]              \n__________________________________________________________________________________________________\nconv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_24[0][0]              \n__________________________________________________________________________________________________\nconv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_22[0][0]              \n__________________________________________________________________________________________________\nconv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nconv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n                                                                 conv4_1_1x1_proj/bn[0][0]        \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n__________________________________________________________________________________________________\nconv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_25[0][0]              \n__________________________________________________________________________________________________\nconv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_26[0][0]              \n__________________________________________________________________________________________________\nconv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_27[0][0]              \n__________________________________________________________________________________________________\nconv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n                                                                 activation_25[0][0]              \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n__________________________________________________________________________________________________\nconv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_28[0][0]              \n__________________________________________________________________________________________________\nconv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_29[0][0]              \n__________________________________________________________________________________________________\nconv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_30[0][0]              \n__________________________________________________________________________________________________\nconv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n                                                                 activation_28[0][0]              \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n__________________________________________________________________________________________________\nconv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_31[0][0]              \n__________________________________________________________________________________________________\nconv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_32[0][0]              \n__________________________________________________________________________________________________\nconv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_33[0][0]              \n__________________________________________________________________________________________________\nconv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n                                                                 activation_31[0][0]              \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n__________________________________________________________________________________________________\nconv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_34[0][0]              \n__________________________________________________________________________________________________\nconv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_35[0][0]              \n__________________________________________________________________________________________________\nconv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_36[0][0]              \n__________________________________________________________________________________________________\nconv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n                                                                 activation_34[0][0]              \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n__________________________________________________________________________________________________\nconv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_37[0][0]              \n__________________________________________________________________________________________________\nconv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_38[0][0]              \n__________________________________________________________________________________________________\nconv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_39[0][0]              \n__________________________________________________________________________________________________\nconv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n                                                                 activation_37[0][0]              \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n__________________________________________________________________________________________________\nconv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_40[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_41[0][0]              \n__________________________________________________________________________________________________\nconv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_42[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_40[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nconv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n                                                                 conv5_1_1x1_proj/bn[0][0]        \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n__________________________________________________________________________________________________\nconv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_43[0][0]              \n__________________________________________________________________________________________________\nconv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_44[0][0]              \n__________________________________________________________________________________________________\nconv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_45[0][0]              \n__________________________________________________________________________________________________\nconv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n                                                                 activation_43[0][0]              \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n__________________________________________________________________________________________________\nconv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_46[0][0]              \n__________________________________________________________________________________________________\nconv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_47[0][0]              \n__________________________________________________________________________________________________\nconv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_48[0][0]              \n__________________________________________________________________________________________________\nconv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_16 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n                                                                 activation_46[0][0]              \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n__________________________________________________________________________________________________\navg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n__________________________________________________________________________________________________\nclassifier (Dense)              (None, 4)            8196        flatten[0][0]                    \n==================================================================================================\nTotal params: 23,569,348\nTrainable params: 23,516,228\nNon-trainable params: 53,120\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 541 samples, validate on 136 samples\nEpoch 1/20\n 32/541 [>.............................] - ETA: 17:29 - loss: 0.7665 - accuracy: 0.2812"
    }
   ],
   "source": [
    "history_1= model.fit(\n",
    "\tx = eyeImage_train,\n",
    "\ty = quaternary_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "\tepochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history_1.history['accuracy'])\n",
    "plt.plot(history_1.history['val_accuracy'])\n",
    "plt.title('model accuracy of vggface2 1')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='upper left')\n",
    "fig1 = plt.gcf()\n",
    "plt.show()\n",
    "plt.draw()\n",
    "fig1.savefig('results/vggface2_1_acc.png')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history_1.history['loss'])\n",
    "plt.plot(history_1.history['val_loss'])\n",
    "plt.title('model loss of vggface2 1tf.keras.utils.to_categorical\n",
    "')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='upper left')\n",
    "fig1 = plt.gcf()\n",
    "plt.show()\n",
    "plt.draw()\n",
    "fig1.savefig('results/vggface2_1_loss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_2 = model.evaluate(eyeImage_test, quaternary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated version of `create_tf_data`, July 1, 2020\n",
    "Substract every image from the average image, every landmarks from the average landmarks positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the mean image of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image = np.mean(eyeImage_train, axis = 0)\n",
    "# meadian_image = np.median(eyeImage_train, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(mean_image)\n",
    "# plt.savefig(\"results/average_img.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated version of `create_tf_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_data(X, Y):\n",
    "    \"\"\"\n",
    "    take in the X and Y and transform each column into np array\n",
    "    Every column in X will be substracted from its mean\n",
    "    \"\"\"\n",
    "    \n",
    "    eyeImage = np.stack(X['eyeImage'].to_numpy())\n",
    "    image_mean = np.mean(eyeImage, axis=0)\n",
    "    eyeImage = eyeImage-image_mean\n",
    "\n",
    "    leftEye = np.stack(X['leftEye'].to_numpy())\n",
    "    leftEye_mean = np.mean(leftEye, axis=0)\n",
    "    leftEye = leftEye-leftEye_mean\n",
    "\n",
    "    rightEye = np.stack(X['rightEye'].to_numpy())\n",
    "    rightEye_mean = np.mean(rightEye, axis=0)\n",
    "    rightEye = rightEye-rightEye_mean\n",
    "\n",
    "    y = np.stack(Y['y'].to_numpy())\n",
    "    return eyeImage, leftEye, rightEye, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that we substract the mean correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,left,_,_ = create_tf_data(x_train, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(left,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "deeplearning",
   "display_name": "Python (deeplearning)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}