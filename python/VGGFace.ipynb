{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %%\n",
    "from cnn_utils import *\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.engine import  Model\n",
    "from keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the installation of Keras VGGFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check version of keras_vggface\n",
    "# import keras_vggface\n",
    "# print version\n",
    "# print(keras_vggface.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                            eyeImage  \\\n0  [[[0.49019607843137253, 0.4627450980392157, 0....   \n1  [[[0.19607843137254902, 0.1607843137254902, 0....   \n2  [[[0.2196078431372549, 0.19215686274509805, 0....   \n3  [[[0.2196078431372549, 0.17647058823529413, 0....   \n4  [[[0.5882352941176471, 0.5647058823529412, 0.6...   \n\n                                             leftEye  \\\n0  [-0.06916704732662149, 0.19730078279591035, -0...   \n1  [-0.17658285534307594, 0.18033866676032262, -0...   \n2  [-0.17382043840055927, 0.17981051564675177, -0...   \n3  [-0.15968611544730582, 0.18524077990937093, -0...   \n4  [-0.07825260742468576, 0.16963032408957468, -0...   \n\n                                            rightEye  \\\n0  [0.17425771877389162, 0.21639015714266296, 0.2...   \n1  [0.06629549190581052, 0.1988126179958256, 0.10...   \n2  [0.06089991895895852, 0.18628686237123016, 0.0...   \n3  [0.08123800929222913, 0.1904861112443328, 0.11...   \n4  [0.1666792245722788, 0.19617187288354976, 0.20...   \n\n                                             y  \n0  [-0.30000000000000004, -0.3019517795637199]  \n1   [0.30000000000000004, -0.9012629161882894]  \n2    [0.8999999999999999, -0.9012629161882894]  \n3   [-0.30000000000000004, 0.8989667049368542]  \n4   [-0.30000000000000004, 0.2996555683122848]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eyeImage</th>\n      <th>leftEye</th>\n      <th>rightEye</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[[0.49019607843137253, 0.4627450980392157, 0....</td>\n      <td>[-0.06916704732662149, 0.19730078279591035, -0...</td>\n      <td>[0.17425771877389162, 0.21639015714266296, 0.2...</td>\n      <td>[-0.30000000000000004, -0.3019517795637199]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[[0.19607843137254902, 0.1607843137254902, 0....</td>\n      <td>[-0.17658285534307594, 0.18033866676032262, -0...</td>\n      <td>[0.06629549190581052, 0.1988126179958256, 0.10...</td>\n      <td>[0.30000000000000004, -0.9012629161882894]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[[0.2196078431372549, 0.19215686274509805, 0....</td>\n      <td>[-0.17382043840055927, 0.17981051564675177, -0...</td>\n      <td>[0.06089991895895852, 0.18628686237123016, 0.0...</td>\n      <td>[0.8999999999999999, -0.9012629161882894]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[[0.2196078431372549, 0.17647058823529413, 0....</td>\n      <td>[-0.15968611544730582, 0.18524077990937093, -0...</td>\n      <td>[0.08123800929222913, 0.1904861112443328, 0.11...</td>\n      <td>[-0.30000000000000004, 0.8989667049368542]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[[0.5882352941176471, 0.5647058823529412, 0.6...</td>\n      <td>[-0.07825260742468576, 0.16963032408957468, -0...</td>\n      <td>[0.1666792245722788, 0.19617187288354976, 0.20...</td>\n      <td>[-0.30000000000000004, 0.2996555683122848]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df = create_dataframe('/../raw_data/dataset_062920.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "846"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to use Quaternary encoding to see if we have mislabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    col1  col2\n0      0    20\n1      1    21\n3      3    23\n5      5    25\n7      7    27\n8      8    28\n9      9    29\n10    10    30\n11    11    31\n12    12    32\n13    13    33\n16    16    36\n18    18    38\n19    19    39",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col1</th>\n      <th>col2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>39</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# d = {'col1': [i for i in range(20)], 'col2': [j for j in range(20,40)]}\n",
    "# df = pd.DataFrame(data=d)\n",
    "# df\n",
    "# train = df.sample(frac=0.7).sort_index()\n",
    "# validation = df.drop(train.index).sort_index()\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'create_train_validation' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-64a2a002a998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# randomly select training examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# generate binary y labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# y_train_binary = create_binary_labels(y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_train_validation' is not defined"
     ]
    }
   ],
   "source": [
    "# randomly select training examples\n",
    "x_train, x_validation, y_train, y_validation = create_train_validation(df)\n",
    "\n",
    "# generate binary y labels\n",
    "# y_train_binary = create_binary_labels(y_train)\n",
    "# y_validation_binary = create_binary_labels(y_validation) # generate binary y labels\n",
    "\n",
    "# generate quaternary y labels\n",
    "y_train_quaternary = create_quaternary_labels(y_train)\n",
    "y_validation_quaternary = create_quaternary_labels(y_validation) # generate binary y labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some data\n",
    "# plot_eyeImages(x_train,y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for feeding in CNN\n",
    "eyeImage_train, leftEye_train, rightEye_train, quaternary_train = create_tf_data(x_train, y_train_quaternary)\n",
    "eyeImage_test, leftEye_test, rightEye_test, quaternary_test = create_tf_data(x_validation, y_validation_quaternary)\n",
    "\n",
    "\n",
    "# encoding the data\n",
    "# binary_encoder = LabelEncoder()\n",
    "# binary_encoder.fit(binary_train)\n",
    "# binary_train = binary_encoder.transform(binary_train)\n",
    "# binary_test = binary_encoder.transform(binary_test)\n",
    "\n",
    "# # one-hot encoding the data\n",
    "# binary_train = to_categorical(binary_train)\n",
    "# binary_test = to_categorical(binary_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 0., 1.],\n       ...,\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [1., 0., 0., 0.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "quaternary_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (677, 4) instead.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-85e9e2e6dcb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquaternary_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mquaternary_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquaternary_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mquaternary_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquaternary_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquaternary_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mquaternary_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquaternary_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquaternary_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    846\u001b[0m     raise ValueError(\n\u001b[1;32m    847\u001b[0m         \u001b[0;34m\"y should be a 1d array, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m         \"got an array of shape {} instead.\".format(shape))\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (677, 4) instead."
     ]
    }
   ],
   "source": [
    "quaternary_encoder = LabelEncoder()\n",
    "quaternary_encoder.fit(quaternary_train)\n",
    "quaternary_train = quaternary_encoder.transform(quaternary_train)\n",
    "quaternary_test = quaternary_encoder.transform(quaternary_test)\n",
    "\n",
    "# one-hot encoding the data\n",
    "quaternary_train = tf.keras.utils.to_categorical(quaternary_train)\n",
    "quaternary_test = tf.keras.utils.to_categorical(quaternary_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 0., 1.],\n       ...,\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [1., 0., 0., 0.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "quaternary_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGFace2 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\nWARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n\n"
    }
   ],
   "source": [
    "baseModel = VGGFace(model='resnet50',input_shape=(224,224,3),include_top=False,weights='vggface', pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "                 \n__________________________________________________________________________________________________\nconv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_22[0][0]              \n__________________________________________________________________________________________________\nconv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_23[0][0]              \n__________________________________________________________________________________________________\nconv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_24[0][0]              \n__________________________________________________________________________________________________\nconv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_22[0][0]              \n__________________________________________________________________________________________________\nconv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nconv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n                                                                 conv4_1_1x1_proj/bn[0][0]        \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n__________________________________________________________________________________________________\nconv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_25[0][0]              \n__________________________________________________________________________________________________\nconv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_26[0][0]              \n__________________________________________________________________________________________________\nconv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_27[0][0]              \n__________________________________________________________________________________________________\nconv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n                                                                 activation_25[0][0]              \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n__________________________________________________________________________________________________\nconv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_28[0][0]              \n__________________________________________________________________________________________________\nconv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_29[0][0]              \n__________________________________________________________________________________________________\nconv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_30[0][0]              \n__________________________________________________________________________________________________\nconv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n                                                                 activation_28[0][0]              \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n__________________________________________________________________________________________________\nconv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_31[0][0]              \n__________________________________________________________________________________________________\nconv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_32[0][0]              \n__________________________________________________________________________________________________\nconv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_33[0][0]              \n__________________________________________________________________________________________________\nconv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n                                                                 activation_31[0][0]              \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n__________________________________________________________________________________________________\nconv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_34[0][0]              \n__________________________________________________________________________________________________\nconv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_35[0][0]              \n__________________________________________________________________________________________________\nconv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_36[0][0]              \n__________________________________________________________________________________________________\nconv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n                                                                 activation_34[0][0]              \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n__________________________________________________________________________________________________\nconv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_37[0][0]              \n__________________________________________________________________________________________________\nconv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_38[0][0]              \n__________________________________________________________________________________________________\nconv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_39[0][0]              \n__________________________________________________________________________________________________\nconv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n                                                                 activation_37[0][0]              \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n__________________________________________________________________________________________________\nconv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_40[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_41[0][0]              \n__________________________________________________________________________________________________\nconv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_42[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_40[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nconv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n                                                                 conv5_1_1x1_proj/bn[0][0]        \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n__________________________________________________________________________________________________\nconv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_43[0][0]              \n__________________________________________________________________________________________________\nconv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_44[0][0]              \n__________________________________________________________________________________________________\nconv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_45[0][0]              \n__________________________________________________________________________________________________\nconv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n                                                                 activation_43[0][0]              \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n__________________________________________________________________________________________________\nconv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_46[0][0]              \n__________________________________________________________________________________________________\nconv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_47[0][0]              \n__________________________________________________________________________________________________\nconv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_48[0][0]              \n__________________________________________________________________________________________________\nconv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_16 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n                                                                 activation_46[0][0]              \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n__________________________________________________________________________________________________\navg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n==================================================================================================\nTotal params: 23,561,152\nTrainable params: 23,508,032\nNon-trainable params: 53,120\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "baseModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.get_layer('avg_pool').output\n",
    "headModel = Flatten(name='flatten')(headModel)\n",
    "headModel = Dense(4, activation='softmax', name='classifier')(headModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "base_learning_rate = 0.0001\n",
    "adam = Adam(learning_rate=base_learning_rate)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0,\n",
    "    reduction=\"auto\",\n",
    "    name=\"categorical_crossentropy\",\n",
    ")\n",
    "\n",
    "model.compile(optimizer=adam,metrics=['accuracy'],loss = loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "uce[0][0]         \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_23[0][0]              \n__________________________________________________________________________________________________\nconv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_24[0][0]              \n__________________________________________________________________________________________________\nconv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_22[0][0]              \n__________________________________________________________________________________________________\nconv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nconv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n                                                                 conv4_1_1x1_proj/bn[0][0]        \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n__________________________________________________________________________________________________\nconv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_25[0][0]              \n__________________________________________________________________________________________________\nconv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_26[0][0]              \n__________________________________________________________________________________________________\nconv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_27[0][0]              \n__________________________________________________________________________________________________\nconv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n                                                                 activation_25[0][0]              \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n__________________________________________________________________________________________________\nconv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_28[0][0]              \n__________________________________________________________________________________________________\nconv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_29[0][0]              \n__________________________________________________________________________________________________\nconv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_30[0][0]              \n__________________________________________________________________________________________________\nconv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n                                                                 activation_28[0][0]              \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n__________________________________________________________________________________________________\nconv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_31[0][0]              \n__________________________________________________________________________________________________\nconv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_32[0][0]              \n__________________________________________________________________________________________________\nconv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_33[0][0]              \n__________________________________________________________________________________________________\nconv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n                                                                 activation_31[0][0]              \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n__________________________________________________________________________________________________\nconv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_34[0][0]              \n__________________________________________________________________________________________________\nconv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_35[0][0]              \n__________________________________________________________________________________________________\nconv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_36[0][0]              \n__________________________________________________________________________________________________\nconv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n                                                                 activation_34[0][0]              \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n__________________________________________________________________________________________________\nconv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_37[0][0]              \n__________________________________________________________________________________________________\nconv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_38[0][0]              \n__________________________________________________________________________________________________\nconv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_39[0][0]              \n__________________________________________________________________________________________________\nconv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n                                                                 activation_37[0][0]              \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n__________________________________________________________________________________________________\nconv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_40[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_41[0][0]              \n__________________________________________________________________________________________________\nconv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_42[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_40[0][0]              \n__________________________________________________________________________________________________\nconv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nconv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n                                                                 conv5_1_1x1_proj/bn[0][0]        \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n__________________________________________________________________________________________________\nconv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_43[0][0]              \n__________________________________________________________________________________________________\nconv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_44[0][0]              \n__________________________________________________________________________________________________\nconv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_45[0][0]              \n__________________________________________________________________________________________________\nconv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n                                                                 activation_43[0][0]              \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n__________________________________________________________________________________________________\nconv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_46[0][0]              \n__________________________________________________________________________________________________\nconv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n__________________________________________________________________________________________________\nconv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_47[0][0]              \n__________________________________________________________________________________________________\nconv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n__________________________________________________________________________________________________\nconv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_48[0][0]              \n__________________________________________________________________________________________________\nconv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n__________________________________________________________________________________________________\nadd_16 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n                                                                 activation_46[0][0]              \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n__________________________________________________________________________________________________\navg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n__________________________________________________________________________________________________\nclassifier (Dense)              (None, 4)            8196        flatten[0][0]                    \n==================================================================================================\nTotal params: 23,569,348\nTrainable params: 8,196\nNon-trainable params: 23,561,152\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nTrain on 541 samples, validate on 136 samples\nEpoch 1/20\n541/541 [==============================] - 59s 108ms/step - loss: 2.1096 - accuracy: 0.2421 - val_loss: 1.4842 - val_accuracy: 0.2353\nEpoch 2/20\n541/541 [==============================] - 51s 95ms/step - loss: 1.9317 - accuracy: 0.2773 - val_loss: 1.4788 - val_accuracy: 0.2353\nEpoch 3/20\n541/541 [==============================] - 50s 93ms/step - loss: 1.7981 - accuracy: 0.2884 - val_loss: 1.4790 - val_accuracy: 0.2353\nEpoch 4/20\n541/541 [==============================] - 53s 97ms/step - loss: 1.7154 - accuracy: 0.3087 - val_loss: 1.4753 - val_accuracy: 0.2353\nEpoch 5/20\n541/541 [==============================] - 53s 98ms/step - loss: 1.6541 - accuracy: 0.3567 - val_loss: 1.4773 - val_accuracy: 0.2353\nEpoch 6/20\n541/541 [==============================] - 50s 92ms/step - loss: 1.5403 - accuracy: 0.3641 - val_loss: 1.4737 - val_accuracy: 0.2353\nEpoch 7/20\n541/541 [==============================] - 52s 95ms/step - loss: 1.4790 - accuracy: 0.3808 - val_loss: 1.4701 - val_accuracy: 0.2353\nEpoch 8/20\n541/541 [==============================] - 50s 92ms/step - loss: 1.4459 - accuracy: 0.3863 - val_loss: 1.4682 - val_accuracy: 0.2353\nEpoch 9/20\n320/541 [================>.............] - ETA: 18s - loss: 1.3235 - accuracy: 0.4281"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6479c4869a3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \tepochs=20)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_1= model.fit(\n",
    "\tx = eyeImage_train,\n",
    "\ty = quaternary_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "\tepochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history_1.history['accuracy'])\n",
    "plt.plot(history_1.history['val_accuracy'])\n",
    "plt.title('model accuracy of vggface2 2')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='upper left')\n",
    "fig1 = plt.gcf()\n",
    "plt.show()\n",
    "plt.draw()\n",
    "fig1.savefig('results/vggface2_2_acc.png')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history_1.history['loss'])\n",
    "plt.plot(history_1.history['val_loss'])\n",
    "plt.title('model loss of vggface2 2')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='upper left')\n",
    "fig1 = plt.gcf()\n",
    "plt.show()\n",
    "plt.draw()\n",
    "fig1.savefig('results/vggface2_2_loss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_2 = model.evaluate(eyeImage_test, quaternary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated version of `create_tf_data`, July 1, 2020\n",
    "Substract every image from the average image, every landmarks from the average landmarks positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the mean image of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image = np.mean(eyeImage_train, axis = 0)\n",
    "# meadian_image = np.median(eyeImage_train, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fbac59bdd10>"
     },
     "metadata": {},
     "execution_count": 22
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"251.831987pt\" version=\"1.1\" viewBox=\"0 0 257.9275 251.831987\" width=\"257.9275pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 251.831987 \nL 257.9275 251.831987 \nL 257.9275 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 227.953862 \nL 250.7275 227.953862 \nL 250.7275 10.513862 \nL 33.2875 10.513862 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p7c0fd09879)\">\n    <image height=\"218\" id=\"image811c343b0c\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"33.2875\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAABHNCSVQICAgIfAhkiAAAAndJREFUeJzt0zEBwCAQwMAH/55bFYSBOwVZsmbmG+CofTsAXmA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIGA0CBgNAkaDgNEgYDQIGA0CRoOA0SBgNAgYDQJGg4DRIPADxugCs1QYlSAAAAAASUVORK5CYII=\" y=\"-9.953862\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mf055889aac\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.772857\" xlink:href=\"#mf055889aac\" y=\"227.953862\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(30.591607 242.552299)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.308571\" xlink:href=\"#mf055889aac\" y=\"227.953862\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(75.946071 242.552299)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"130.844286\" xlink:href=\"#mf055889aac\" y=\"227.953862\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(121.300536 242.552299)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"179.38\" xlink:href=\"#mf055889aac\" y=\"227.953862\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(169.83625 242.552299)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"227.915714\" xlink:href=\"#mf055889aac\" y=\"227.953862\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(218.371964 242.552299)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mff0156e49b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mff0156e49b\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mff0156e49b\" y=\"35.267076\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 25 -->\n      <g transform=\"translate(13.5625 39.066295)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mff0156e49b\" y=\"59.534933\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 50 -->\n      <g transform=\"translate(13.5625 63.334152)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mff0156e49b\" y=\"83.80279\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 75 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(13.5625 87.602009)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mff0156e49b\" y=\"108.070647\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 111.869866)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mff0156e49b\" y=\"132.338504\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 125 -->\n      <g transform=\"translate(7.2 136.137723)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mff0156e49b\" y=\"156.606362\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 150 -->\n      <g transform=\"translate(7.2 160.40558)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mff0156e49b\" y=\"180.874219\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 175 -->\n      <g transform=\"translate(7.2 184.673437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mff0156e49b\" y=\"205.142076\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 208.941295)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 227.953862 \nL 33.2875 10.513862 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 250.7275 227.953862 \nL 250.7275 10.513862 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 227.953862 \nL 250.7275 227.953862 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 10.513862 \nL 250.7275 10.513862 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7c0fd09879\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"33.2875\" y=\"10.513862\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.imshow(mean_image)\n",
    "# plt.savefig(\"results/average_img.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated version of `create_tf_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_data(X, Y):\n",
    "    \"\"\"\n",
    "    take in the X and Y and transform each column into np array\n",
    "    Every column in X will be substracted from its mean\n",
    "    \"\"\"\n",
    "    \n",
    "    eyeImage = np.stack(X['eyeImage'].to_numpy())\n",
    "    image_mean = np.mean(eyeImage, axis=0)\n",
    "    eyeImage = eyeImage-image_mean\n",
    "\n",
    "    leftEye = np.stack(X['leftEye'].to_numpy())\n",
    "    leftEye_mean = np.mean(leftEye, axis=0)\n",
    "    leftEye = leftEye-leftEye_mean\n",
    "\n",
    "    rightEye = np.stack(X['rightEye'].to_numpy())\n",
    "    rightEye_mean = np.mean(rightEye, axis=0)\n",
    "    rightEye = rightEye-rightEye_mean\n",
    "\n",
    "    y = np.stack(Y['y'].to_numpy())\n",
    "    return eyeImage, leftEye, rightEye, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that we substract the mean correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'y_train_binary' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b0d1a9bf2f26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tf_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_binary' is not defined"
     ]
    }
   ],
   "source": [
    "_,left,_,_ = create_tf_data(x_train, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'left' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-dfb54683ea6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'left' is not defined"
     ]
    }
   ],
   "source": [
    "np.sum(left,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitdeeplearningconda4b0c41a6e27a4316b033213401f783f9",
   "display_name": "Python 3.7.7 64-bit ('deeplearning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}