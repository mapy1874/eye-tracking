{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the current dir so the sys know the .py modules\n",
    "import os\n",
    "os.chdir('/Users/patrick/OneDrive - University of North Carolina at Chapel Hill/SMART_research/lookie-lookie/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "import base64\n",
    "import cv2\n",
    "import random\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cnn_utils import *\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get(\"https://gb.cs.unc.edu/json/drop\",headers= { \"Accept\": \"application/json\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_ids = []\n",
    "for drop in data.json()['drops']:\n",
    "    available_ids.append(drop['id'])\n",
    "# available_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to exclude the bad IDs. Here we hardcode the bad IDs by using our [image filter website](http://patrickma.me/simple_filter/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = [87,88,123,124,125,126,127,128,129,132,133,134,135,136,137,138,148,149,150,151,152,153,156,157,158,159,160,161,166,167,168,169,171,172,173,174,175,176,177,178,179,180,181,182,185,186,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,251,252,253,254,255,256,257,258,259,260,261,262,264,265,266,267,268,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,467,468,488,489,491,492,500,501,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [x for x in available_ids if x not in bad_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = []\n",
    "for valid_id in valid_ids:\n",
    "    data = requests.get('https://gb.cs.unc.edu/json/drop/'+str(valid_id))\n",
    "    allData.append(data.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the valid data to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../raw_data/dataset_062920.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(allData, f, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataframe('/../raw_data/dataset_062920.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = create_train_validation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary y labels\n",
    "y_train_binary = create_binary_labels(y_train)\n",
    "y_validation_binary = create_binary_labels(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eyeImages(x_train,y_train_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = x_train[\"eyeImage\"].iloc[0].shape[1]\n",
    "IMG_HEIGHT = x_train[\"eyeImage\"].iloc[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward_propagation(eyeImage, leftEye, rightEye):\n",
    "#     \"\"\"\n",
    "#     Implements the forward propagation for the model:\n",
    "#     CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "#     Note that for simplicity and grading purposes, we'll hard-code some values\n",
    "#     such as the stride and kernel (filter) sizes. \n",
    "#     Normally, functions should take these values as function parameters.\n",
    "    \n",
    "#     Arguments:\n",
    "\n",
    "#     Returns:\n",
    "#     Z3 -- the output of the last LINEAR unit\n",
    "#     \"\"\"\n",
    "# #     eyeImage = tf.keras.layers.Input(shape=(IMG_HEIGHT,IMG_WIDTH, 3))\n",
    "# #     leftEye = tf.keras.layers.Input(shape=(12)) # requires the eye positions to be flattened to 1D\n",
    "# #     rightEye = tf.keras.layers.Input(shape=(12))\n",
    "#     conv = tf.keras.layers.Conv2D(filters=20, kernel_size=5, strides=1, activation='relu', kernel_initializer='VarianceScaling')(eyeImage)\n",
    "#     maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(conv)\n",
    "#     flat = tf.keras.layers.Flatten()(maxpool)\n",
    "#     drop = tf.keras.layers.Dropout(rate=0.2)(flat)\n",
    "#     concat = tf.keras.layers.concatenate([drop, leftEye, rightEye])\n",
    "#     out = tf.keras.layers.Dense(units=2,activation=\"tanh\",kernel_initializer='VarianceScaling')(concat)\n",
    "\n",
    "#     simple_model = tf.keras.Model(inputs=[eyeImage, leftEye, rightEye], outputs=out, name=\"SimpleModel\")\n",
    "#     simple_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),loss = tf.keras.losses.MeanSquaredError())\n",
    "    \n",
    "#     return simple_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(x_train[\"eyeImage\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df.pop('y')\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))\n",
    "data = {'X1':  [[1,2,3], [3,4,5]],\n",
    "        'X2': [['a','b','c'],['c','d','e']]}\n",
    "df = pd.DataFrame(data)\n",
    "np.array(df)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_data(X, Y):\n",
    "    \"\"\"\n",
    "    take in the X and Y and transform each column into np array\n",
    "    \"\"\"\n",
    "    \n",
    "    eyeImage = np.stack(X['eyeImage'].to_numpy())\n",
    "    leftEye = np.stack(X['leftEye'].to_numpy())\n",
    "    rightEye = np.stack(X['rightEye'].to_numpy())\n",
    "    y = np.stack(Y['y'].to_numpy())\n",
    "    return eyeImage, leftEye, rightEye, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeImage_train, leftEye_train, rightEye_train, binary_train = create_tf_data(x_train, y_train_binary)\n",
    "eyeImage_test, leftEye_test, rightEye_test, binary_test = create_tf_data(x_validation, y_validation_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the y label to make it suitable for CNN\n",
    "binary_encoder = LabelEncoder()\n",
    "binary_encoder.fit(binary_train)\n",
    "binary_train = binary_encoder.transform(binary_train)\n",
    "binary_test = binary_encoder.transform(binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeImage = tf.keras.layers.Input(shape=(IMG_HEIGHT,IMG_WIDTH, 3))\n",
    "leftEye = tf.keras.layers.Input(shape=(12)) # requires the eye positions to be flattened to 1D\n",
    "rightEye = tf.keras.layers.Input(shape=(12))\n",
    "\n",
    "conv = tf.keras.layers.Conv2D(filters=20, kernel_size=5, strides=1, activation='relu', kernel_initializer='VarianceScaling')(eyeImage)\n",
    "maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(conv)\n",
    "flat = tf.keras.layers.Flatten()(maxpool)\n",
    "drop = tf.keras.layers.Dropout(rate=0.2)(flat)\n",
    "concat = tf.keras.layers.concatenate([drop, leftEye, rightEye])\n",
    "dense = tf.keras.layers.Dense(units=128,activation=\"relu\",kernel_initializer='VarianceScaling')(concat)\n",
    "out = tf.keras.layers.Dense(units=1,activation=\"sigmoid\")(dense)\n",
    "simple_model = tf.keras.Model(inputs=[eyeImage, leftEye, rightEye], outputs=out, name=\"SimpleModel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),metrics=['accuracy'],loss = tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.fit([eyeImage_train, leftEye_train, rightEye_train], binary_train, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = simple_model.evaluate([eyeImage_test, leftEye_test, rightEye_test], binary_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}