{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the current dir so the sys know the .py modules\n",
    "import os\n",
    "os.chdir('/home/jupyter/eye-tracking/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "import base64\n",
    "import cv2\n",
    "import random\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cnn_utils import *\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get(\"https://gb.cs.unc.edu/json/drop\",headers= { \"Accept\": \"application/json\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_ids = []\n",
    "for drop in data.json()['drops']:\n",
    "    available_ids.append(drop['id'])\n",
    "# available_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to exclude the bad IDs. Here we hardcode the bad IDs by using our [image filter website](http://patrickma.me/simple_filter/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = [87,88,123,124,125,126,127,128,129,132,133,134,135,136,137,138,148,149,150,151,152,153,156,157,158,159,160,161,166,167,168,169,171,172,173,174,175,176,177,178,179,180,181,182,185,186,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,251,252,253,254,255,256,257,258,259,260,261,262,264,265,266,267,268,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,467,468,488,489,491,492,500,501,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [x for x in available_ids if x not in bad_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = []\n",
    "for valid_id in valid_ids:\n",
    "    data = requests.get('https://gb.cs.unc.edu/json/drop/'+str(valid_id))\n",
    "    allData.append(data.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the valid data to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../raw_data/dataset_062920.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(allData, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def create_dataframe(relative_dir ='/../raw_data/dataset_062120.json' ):\n",
      "    \"\"\"\n",
      "    convert the JSON file of my research into a dataframe with the following columns:\n",
      "    eyeImage: np array with shape (25, 50, 3)\n",
      "    leftEye: np array with shape (6,2): 6 left eye landmarks positions in the form of (x,y), where -1<=x,y<=1\n",
      "    rightEye: np array with shape (6,2): 6 right eye landmarks positions in the form of (x,y), where -1<=x,y<=1\n",
      "    y: the position that the user looks at on the screen in the form of (x,y), where -1<=x,y<=1\n",
      "    \"\"\"\n",
      "    f = open(os.path.join(os.path.dirname(__file__))+relative_dir)\n",
      "    eyeImages,leftEyes,rightEyes,ys = [], [], [], []\n",
      "    for item in ijson.items(f, \"item\"):\n",
      "        # convert the string into a python dict\n",
      "        temp = json.loads(item) \n",
      "        # convert the image into the np array\n",
      "        eyeImage = convert_base64_to_nparray(temp[\"x\"][\"eyeImage\"])\n",
      "        eyeImages.append(eyeImage)\n",
      "\n",
      "        leftEye = np.array(temp[\"x\"][\"eyePositions\"][\"leftEye\"]).reshape(12)\n",
      "        leftEyes.append(leftEye)\n",
      "        rightEye = np.array(temp[\"x\"][\"eyePositions\"][\"rightEye\"]).reshape(12)\n",
      "        rightEyes.append(rightEye)\n",
      "\n",
      "        y = np.array(temp[\"y\"])\n",
      "        ys.append(y)\n",
      "\n",
      "    list_of_tuples = list(zip(eyeImages,leftEyes,rightEyes,ys))\n",
      "    df = pd.DataFrame(list_of_tuples, columns =['eyeImage','leftEye', 'rightEye', 'y'])\n",
      "    return df\n"
     ]
    }
   ],
   "source": [
    "import inspect as i\n",
    "import sys\n",
    "sys.stdout.write(i.getsource(create_dataframe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e03ccc5efea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/../raw_data/dataset_062920.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eye-tracking/python/cnn_utils.py\u001b[0m in \u001b[0;36mcreate_dataframe\u001b[0;34m(relative_dir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mijson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"item\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# convert the string into a python dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;31m# convert the image into the np array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0meyeImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_base64_to_nparray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eyeImage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n\u001b[0m\u001b[1;32m    342\u001b[0m                             f'not {s.__class__.__name__}')\n\u001b[1;32m    343\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetect_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogatepass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not dict"
     ]
    }
   ],
   "source": [
    "df = create_dataframe('/../raw_data/dataset_062920.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = create_train_validation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary y labels\n",
    "y_train_binary = create_binary_labels(y_train)\n",
    "y_validation_binary = create_binary_labels(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eyeImages(x_train,y_train_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = x_train[\"eyeImage\"].iloc[0].shape[1]\n",
    "IMG_HEIGHT = x_train[\"eyeImage\"].iloc[0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward_propagation(eyeImage, leftEye, rightEye):\n",
    "#     \"\"\"\n",
    "#     Implements the forward propagation for the model:\n",
    "#     CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "#     Note that for simplicity and grading purposes, we'll hard-code some values\n",
    "#     such as the stride and kernel (filter) sizes. \n",
    "#     Normally, functions should take these values as function parameters.\n",
    "    \n",
    "#     Arguments:\n",
    "\n",
    "#     Returns:\n",
    "#     Z3 -- the output of the last LINEAR unit\n",
    "#     \"\"\"\n",
    "# #     eyeImage = tf.keras.layers.Input(shape=(IMG_HEIGHT,IMG_WIDTH, 3))\n",
    "# #     leftEye = tf.keras.layers.Input(shape=(12)) # requires the eye positions to be flattened to 1D\n",
    "# #     rightEye = tf.keras.layers.Input(shape=(12))\n",
    "#     conv = tf.keras.layers.Conv2D(filters=20, kernel_size=5, strides=1, activation='relu', kernel_initializer='VarianceScaling')(eyeImage)\n",
    "#     maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(conv)\n",
    "#     flat = tf.keras.layers.Flatten()(maxpool)\n",
    "#     drop = tf.keras.layers.Dropout(rate=0.2)(flat)\n",
    "#     concat = tf.keras.layers.concatenate([drop, leftEye, rightEye])\n",
    "#     out = tf.keras.layers.Dense(units=2,activation=\"tanh\",kernel_initializer='VarianceScaling')(concat)\n",
    "\n",
    "#     simple_model = tf.keras.Model(inputs=[eyeImage, leftEye, rightEye], outputs=out, name=\"SimpleModel\")\n",
    "#     simple_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),loss = tf.keras.losses.MeanSquaredError())\n",
    "    \n",
    "#     return simple_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(x_train[\"eyeImage\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df.pop('y')\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))\n",
    "data = {'X1':  [[1,2,3], [3,4,5]],\n",
    "        'X2': [['a','b','c'],['c','d','e']]}\n",
    "df = pd.DataFrame(data)\n",
    "np.array(df)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_data(X, Y):\n",
    "    \"\"\"\n",
    "    take in the X and Y and transform each column into np array\n",
    "    \"\"\"\n",
    "    \n",
    "    eyeImage = np.stack(X['eyeImage'].to_numpy())\n",
    "    leftEye = np.stack(X['leftEye'].to_numpy())\n",
    "    rightEye = np.stack(X['rightEye'].to_numpy())\n",
    "    y = np.stack(Y['y'].to_numpy())\n",
    "    return eyeImage, leftEye, rightEye, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeImage_train, leftEye_train, rightEye_train, binary_train = create_tf_data(x_train, y_train_binary)\n",
    "eyeImage_test, leftEye_test, rightEye_test, binary_test = create_tf_data(x_validation, y_validation_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the y label to make it suitable for CNN\n",
    "binary_encoder = LabelEncoder()\n",
    "binary_encoder.fit(binary_train)\n",
    "binary_train = binary_encoder.transform(binary_train)\n",
    "binary_test = binary_encoder.transform(binary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeImage = tf.keras.layers.Input(shape=(IMG_HEIGHT,IMG_WIDTH, 3))\n",
    "leftEye = tf.keras.layers.Input(shape=(12)) # requires the eye positions to be flattened to 1D\n",
    "rightEye = tf.keras.layers.Input(shape=(12))\n",
    "\n",
    "conv = tf.keras.layers.Conv2D(filters=20, kernel_size=5, strides=1, activation='relu', kernel_initializer='VarianceScaling')(eyeImage)\n",
    "maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(conv)\n",
    "flat = tf.keras.layers.Flatten()(maxpool)\n",
    "drop = tf.keras.layers.Dropout(rate=0.2)(flat)\n",
    "concat = tf.keras.layers.concatenate([drop, leftEye, rightEye])\n",
    "dense = tf.keras.layers.Dense(units=128,activation=\"relu\",kernel_initializer='VarianceScaling')(concat)\n",
    "out = tf.keras.layers.Dense(units=1,activation=\"sigmoid\")(dense)\n",
    "simple_model = tf.keras.Model(inputs=[eyeImage, leftEye, rightEye], outputs=out, name=\"SimpleModel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),metrics=['accuracy'],loss = tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.fit([eyeImage_train, leftEye_train, rightEye_train], binary_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = simple_model.evaluate([eyeImage_test, leftEye_test, rightEye_test], binary_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
